#### 视频基础知识

视频：由一组图像组成，为了传输/占用更小的空间而被压缩，最终在显示设备上展示

图像：由像素组成，像素由RGB组成，分辨率

RGB888 24bit；RGBA 32bit。1字节(byte)=8位(bit)

BMP使用的是BGR格式，而不是RGB格式，需要进行转换

屏幕指标：

- PPI：每英寸的像素数量，表示的屏幕质量
- PPI > 300就属于视网膜级别

##### 码流的计算：

- 分辨率

  X轴的像素个数 * Y轴的像素个数，常见的宽高比16:9 / 4:3，360P/720P/1K/2K分辨率

- 帧率

  每秒钟采集/播放图像的个数

  动画的帧率是25帧/s，实时通讯15帧/s，录课30帧/s，电影60帧/s

未编码视频的RGB码流 = 分辨率 * RBG3字节(byte) * 帧率

未编码与H264视频编码的码流压缩比是多少？ 

图像的显示

- 图像大小等于显示区域大小
- 图像小于显示区域：拉伸/留白
- 图像大于显示区域：缩小/截断

##### 什么是YUV

YUV也称YCbCr：Y表示明亮度，UV的作用是描述影像色彩及饱和度

主要的采样格式有**YUV4:2:0**、YUV4:2:2、YUV4:4:4

YUV4:2:0是应用最广泛的格式，所有的播放器基本上都支持。YUV4:4:4部分播放器不支持

YUV4:2:0并不意味着只有Y、Cb两个分量，而没有Cr分量。它实际指的是对每行扫描线来说，只有一种色度分量，它以2:1的抽样率存储。相邻的扫描行存储不同的色度分量，也就是说，如果一行是4:2:0的话，下一行就是4:0:2，再下一行是4:2:0，以此类推

数据量计算：

- YUV4:2:0 = Y * 1.5
- YUV4:2:0 = RGB / 2

##### RBG与YUV的关系

- RGB用于屏幕图像的展示
- YUV用于采集与编码
- RBG转YUV公式和YUV转RBG公式

YUV4:2:0存储格式，分为平面存储(planar)和打包存储(packed)

- 平面存储(planar)
  - I420
  - YV12：iOS
- 打包存储(packed)
  - NV12
  - NV21：Android

未编码视频的YUV码流 = 分辨率 * 1.5字节(byte) * 帧率

未编码视频的RGB码流 = 分辨率 * 3字节(byte) * 帧率

##### 生成YUV数据

1. 从摄像头采集YUV数据
2. 从多媒体文件抽取出YUV数据

```shell
# -an：没有音频
# -c:v rawvideo：视频编码器
# -pix_fmt yuv420p：指定YUV格式
ffplay china.mp4
ffmpeg -i china.mp4 -an -c:v rawvideo -pix_fmt yuv420p out.yuv
ls -alt out.yuv
# -s 608*368：指定分辨率
ffplay -pix_fmt yuv420p -s 608*368 out.yuv
# 播放Y分量
ffplay -pix_fmt yuv420p -s 608*368 -vf extractplanes='y' out.yuv
# 提取各分量
ffmpeg -i xxx.mp4 -filter_complex 'extractplanes=y+u+v[y][u][v]' -map '[y]' y.yuv -map '[u]' u.yuv -map '[v]' v.yuv
# 播放Y分量
ffplay -pix_fmt gray -s 608*368 -vf out.yuv
```

```shell
# 参考：https://www.cnblogs.com/vczf/p/13450998.html
# 使用多媒体文件生成YUV
ffmpeg -i china.mp4 -an -c:v rawvideo -pix_fmt yuv420p out.yuv
# 播放YUV
ffplay -pixel_format yuv420p -video_size 960x540 out.yuv
# 播放Y分量
ffplay -pixel_format yuv420p -video_size 960x540 -vf extractplanes='y' out.yuv
# 提取各分量
ffmpeg -i girl.mp4 -filter_complex 'extractplanes=y+u+v[y][u][v]' -map '[y]' y.yuv -map '[u]' u.yuv -map '[v]' v.yuv
# 播放Y分量
ffplay -pixel_format gray -video_size 1920x1080 y.yuv
# 播放U分量，注意分辨率全部除以2
ffplay -pixel_format gray -video_size 960x540 u.yuv
```

#### 实战：从视频设备上采集YUV数据

在采集音频的代码上稍作修改

- 修改设备名称
- 增加参数
- 修改文件名称及文件数据的大小

```c
// ffplay -pixel_format uyvy422 -s 640x480 video.yuv
#include <stdio.h>
#include <libavutil/log.h>
#include <libavutil/avutil.h>
#include <libavdevice/avdevice.h>
#include <libavformat/avformat.h>
#include <libavcodec/avcodec.h>

int main(int argc, char* argv[]){
    int ret = 0;
  	char errors[1024] = {0, };
  	AVFormatContext *fmt_ctx = NULL;
  	AVDictionary *options = NULL;
		// 采集视频，mac上0代表机器的摄像头，1代表桌面
  	char *devicename = "0";
  	// set log level
		av_log_set_level(AV_LOG_DEBUG);
  	// register video and audio device
  	avdevice_register_all();
  	// get format
  	AVInputFormat *iformat = av_find_input_format("avfoundation");
  	// set options
  	av_dict_set(&options, "video_size", "640*480", 0); 		// 设置分辨率
  	av_dict_set(&options, "framerate", "30", 0); 					// 设置帧率
  	av_dict_set(&options, "pixel_format", "uyvy422", 0);	// 设置格式
  	// open device
  	if((ret = avformat_open_input(&fmt_ctx, devicename, iformat, &options)) < 0){
      	av_strerror(ret, errors, 1024);
      	printf(stderror, "Failed to open video device, [%d]%s\n", ret, errors);
      	return;
    }
  	int count = 0;
    AVPacket pkt;
  	av_init_packet(&pkt);
  	// create file 
  	char *out = "/Users/sec/Downloads/av_base/video.yuv";
  	FILE *outfile = fopen(out, "wb+");
  	// read data from device
  	while((ret = av_read_frame(fmt_ctx, &pkt) && count++ < 500) == 0){
      	// write file
      	// 宽 * 高 * yuv420=1.5/yuv422=2/yuv444=3
      	fwrite(pkt.data, 1, 614400, outfile);
      	fflush(outfile);
				av_log(NULL, AV_LOG_INFO, "pkt size is %d(%p), count=%d \n", pkt.size, pkt.data, count);
  			// release pkt
      	av_packet_unref(&pkt);
    }
  	// close file
  	fclose(outfile);
  	// close device and release ctx
  	avformat_close_input(&fmt_ctx);
  	av_log(NULL, AV_LOG_INFO, "finish \n");
		return 0;
}
```

